{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:02:06.265532Z",
     "start_time": "2025-10-04T14:02:06.261977Z"
    }
   },
   "source": [
    "# You can set them inline\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:02:06.976486Z",
     "start_time": "2025-10-04T14:02:06.966250Z"
    }
   },
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../../.env\", override=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:02:10.618137Z",
     "start_time": "2025-10-04T14:02:08.302478Z"
    }
   },
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset = client.clone_public_dataset(\n",
    "  \"https://smith.langchain.com/public/9078d2f1-7bef-4ba7-b795-210a17682ef9/d\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nithurshen/SNU/intro-to-langsmith/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:03:33.475656Z",
     "start_time": "2025-10-04T14:03:33.315784Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "SUMMARIZATION_SYSTEM_PROMPT = \"\"\"You are a judge, aiming to score how well a summary summarizes the content of a transcript\"\"\"\n",
    "\n",
    "SUMMARIZATION_HUMAN_PROMPT = \"\"\"\n",
    "[The Meeting Transcript] {transcript}\n",
    "[The Start of Summarization] {summary} [The End of Summarization]\"\"\"\n",
    "\n",
    "class SummarizationScore(BaseModel):\n",
    "    score: int = Field(description=\"\"\"A score from 1-10 ranking how good the summarization is and a score from 1-10 for how verbose the summarization is for the provided transcript, with 1 being low, and 10 being high, and return nearest integer of the harmonic mean of both the scores\"\"\")\n",
    "    \n",
    "def summary_score_evaluator(inputs: dict, outputs: dict) -> list:\n",
    "    completion = openai_client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {   \n",
    "                \"role\": \"system\",\n",
    "                \"content\": SUMMARIZATION_SYSTEM_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": SUMMARIZATION_HUMAN_PROMPT.format(\n",
    "                    transcript=inputs[\"transcript\"],\n",
    "                    summary=outputs.get(\"output\", \"N/A\"),\n",
    "                )}\n",
    "        ],\n",
    "        response_format=SummarizationScore,\n",
    "    )\n",
    "\n",
    "    summary_score = completion.choices[0].message.parsed.score\n",
    "    return {\"key\": \"summary_score\", \"score\": summary_score}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:04:03.897455Z",
     "start_time": "2025-10-04T14:03:37.481010Z"
    }
   },
   "source": [
    "# Prompt One: Good Prompt!\n",
    "def good_summarizer(inputs: dict):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Concisely summarize this meeting in 3 sentences. Make sure to include all of the important events. Meeting: {inputs['transcript']}\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "client.evaluate(\n",
    "    good_summarizer,\n",
    "    data=dataset,\n",
    "    evaluators=[summary_score_evaluator],\n",
    "    experiment_prefix=\"Good Summarizer\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nithurshen/SNU/intro-to-langsmith/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Good Summarizer-1024c904' at:\n",
      "https://smith.langchain.com/o/b596d003-75cc-4859-ab5f-9c3358306b32/datasets/60f339fb-ae6f-4ca0-a9c9-94953f4bcf09/compare?selectedSessions=b1e4fb74-4869-465e-aca4-ca0b28dc0d20\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:24,  4.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExperimentResults Good Summarizer-1024c904>"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.transcript</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>feedback.summary_score</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob and Mr. Johnson (CLOSED DEAL): Bob: Good m...</td>\n",
       "      <td>Bob welcomed Mr. Johnson to Ford Motors, where...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>3.058516</td>\n",
       "      <td>2e3f8857-6be6-4431-9c4e-46436ecdfeea</td>\n",
       "      <td>5f3c69c6-b93b-4442-aebf-0f3d26415fca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob and Ms. Nguyen (NO DEAL): Bob: Good aftern...</td>\n",
       "      <td>Bob and Ms. Nguyen discussed her interest in p...</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>2.407825</td>\n",
       "      <td>74118d6b-20db-40c2-b5ac-280f3962e326</td>\n",
       "      <td>c51ac1d8-c3c0-4726-9853-d053e2684b5f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob and Ms. Thompson (NO DEAL): Bob: Hi, Ms. T...</td>\n",
       "      <td>Bob welcomed Ms. Thompson to Ford Motors and d...</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>2.228500</td>\n",
       "      <td>c6712f5c-f3af-4391-ab11-2c4db93de1fe</td>\n",
       "      <td>2b4d3103-2223-4f6a-aaf7-10f6b8b1aaad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob and Mr. Carter (CLOSED DEAL): Bob: Welcome...</td>\n",
       "      <td>Bob welcomed Mr. Carter, who was interested in...</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>10.213989</td>\n",
       "      <td>e2ff36b9-d86f-473d-b0dd-050bd00cea0f</td>\n",
       "      <td>5ddf9dcc-143d-432c-b84e-158f6a33267a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob and Mr. Patel (CLOSED DEAL): Bob: Hello, M...</td>\n",
       "      <td>Bob and Mr. Patel discussed Mr. Patel's intere...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.297066</td>\n",
       "      <td>fe532f77-d464-4a15-a53f-6c5152593ba9</td>\n",
       "      <td>b8abfee5-a9ed-4926-b3c5-c5b8f0c384ec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:04:16.131271Z",
     "start_time": "2025-10-04T14:04:03.901109Z"
    }
   },
   "source": [
    "# Prompt Two: Worse Prompt!\n",
    "def bad_summarizer(inputs: dict):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Summarize this in one sentence. {inputs['transcript']}\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "client.evaluate(\n",
    "    bad_summarizer,\n",
    "    data=dataset,\n",
    "    evaluators=[summary_score_evaluator],\n",
    "    experiment_prefix=\"Bad Summarizer\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Bad Summarizer-8259e244' at:\n",
      "https://smith.langchain.com/o/b596d003-75cc-4859-ab5f-9c3358306b32/datasets/60f339fb-ae6f-4ca0-a9c9-94953f4bcf09/compare?selectedSessions=1c65e4db-2ff2-4b42-8935-7c0229be7296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExperimentResults Bad Summarizer-8259e244>"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.transcript</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>feedback.summary_score</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob and Mr. Johnson (CLOSED DEAL): Bob: Good m...</td>\n",
       "      <td>Bob successfully sold a Ford Explorer to Mr. J...</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>1.687842</td>\n",
       "      <td>2e3f8857-6be6-4431-9c4e-46436ecdfeea</td>\n",
       "      <td>0a7ae207-9f6f-4995-884f-0e5a50247caf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob and Ms. Nguyen (NO DEAL): Bob: Good aftern...</td>\n",
       "      <td>Bob and Ms. Nguyen discussed various car optio...</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>1.340187</td>\n",
       "      <td>74118d6b-20db-40c2-b5ac-280f3962e326</td>\n",
       "      <td>04425c21-8f1b-4a7d-a339-f855026ca3ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob and Ms. Thompson (NO DEAL): Bob: Hi, Ms. T...</td>\n",
       "      <td>Bob introduces Ms. Thompson to Ford Motors, di...</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.007800</td>\n",
       "      <td>c6712f5c-f3af-4391-ab11-2c4db93de1fe</td>\n",
       "      <td>08d7869b-265f-47c8-bfe4-5a1f713361a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob and Mr. Carter (CLOSED DEAL): Bob: Welcome...</td>\n",
       "      <td>Bob successfully helped Mr. Carter trade in hi...</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>1.387726</td>\n",
       "      <td>e2ff36b9-d86f-473d-b0dd-050bd00cea0f</td>\n",
       "      <td>95dd6c81-b082-4768-a538-d2542b0454b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob and Mr. Patel (CLOSED DEAL): Bob: Hello, M...</td>\n",
       "      <td>Bob helped Mr. Patel find and test drive a For...</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.912100</td>\n",
       "      <td>fe532f77-d464-4a15-a53f-6c5152593ba9</td>\n",
       "      <td>92745967-ef1b-4ca1-ad22-d6464a246c71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:04:39.139308Z",
     "start_time": "2025-10-04T14:04:39.137250Z"
    }
   },
   "source": [
    "JUDGE_SYSTEM_PROMPT = \"\"\"\n",
    "Please act as an impartial judge and evaluate the quality of the summarizations provided by two AI summarizers to the meeting transcript below.\n",
    "Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of their summarizations. \n",
    "Begin your evaluation by comparing the two summarizations and provide a short explanation. \n",
    "Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. \n",
    "Do not favor certain names of the assistants. \n",
    "Be as objective as possible. \"\"\"\n",
    "\n",
    "JUDGE_HUMAN_PROMPT = \"\"\"\n",
    "[The Meeting Transcript] {transcript}\n",
    "\n",
    "[The Start of Assistant A's Summarization] {answer_a} [The End of Assistant A's Summarization]\n",
    "\n",
    "[The Start of Assistant B's Summarization] {answer_b} [The End of Assistant B's Summarization]\"\"\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:04:40.326002Z",
     "start_time": "2025-10-04T14:04:40.318527Z"
    }
   },
   "source": [
    "from langsmith.schemas import Example, Run\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Preference(BaseModel):\n",
    "    preference: int = Field(description=\"\"\"1 if Assistant A answer is better based upon the factors above.\n",
    "2 if Assistant B answer is better based upon the factors above.\n",
    "Output 0 if it is a tie.\"\"\")\n",
    "\n",
    "def ranked_preference(runs: list[Run], example: Example) -> dict: # Changed type hint for clarity\n",
    "    answer_a = runs[0].outputs.get(\"output\", \"N/A\")\n",
    "    answer_b = runs[1].outputs.get(\"output\", \"N/A\")\n",
    "\n",
    "    completion = openai_client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": JUDGE_SYSTEM_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": JUDGE_HUMAN_PROMPT.format(\n",
    "                    transcript=example.inputs[\"transcript\"],\n",
    "                    answer_a=answer_a,\n",
    "                    answer_b=answer_b,\n",
    "                )}\n",
    "        ],\n",
    "        response_format=Preference,\n",
    "    )\n",
    "\n",
    "    preference_score = completion.choices[0].message.parsed.preference\n",
    "\n",
    "    # Create a dictionary mapping run IDs to scores instead of a list\n",
    "    if preference_score == 1:\n",
    "        scores = {runs[0].id: 1, runs[1].id: 0}\n",
    "    elif preference_score == 2:\n",
    "        scores = {runs[0].id: 0, runs[1].id: 1}\n",
    "    else:\n",
    "        scores = {runs[0].id: 0, runs[1].id: 0}\n",
    "\n",
    "    return {\"key\": \"preference\", \"scores\": scores}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T14:05:17.611263Z",
     "start_time": "2025-10-04T14:04:59.172291Z"
    }
   },
   "source": [
    "from langsmith import evaluate\n",
    "\n",
    "evaluate(\n",
    "    (\"Good Summarizer-1024c904\", \"Bad Summarizer-8259e244\"),  # TODO: Replace with the names/IDs of your experiments\n",
    "    evaluators=[ranked_preference]\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/b596d003-75cc-4859-ab5f-9c3358306b32/datasets/60f339fb-ae6f-4ca0-a9c9-94953f4bcf09/compare?selectedSessions=b1e4fb74-4869-465e-aca4-ca0b28dc0d20%2C1c65e4db-2ff2-4b42-8935-7c0229be7296&comparativeExperiment=7fafd1e1-4f90-4cd8-a057-e2c0b5294454\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langsmith.evaluation._runner.ComparativeExperimentResults at 0x10ed842b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
