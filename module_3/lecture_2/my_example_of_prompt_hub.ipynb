{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:21:33.553167Z",
     "start_time": "2025-10-06T11:21:33.549638Z"
    }
   },
   "cell_type": "code",
   "source": "import os",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:21:34.142748Z",
     "start_time": "2025-10-06T11:21:34.132250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../../.env\", override=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:21:53.615973Z",
     "start_time": "2025-10-06T11:21:53.277488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"f1_driver_name\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:21:56.714021Z",
     "start_time": "2025-10-06T11:21:56.709227Z"
    }
   },
   "cell_type": "code",
   "source": "prompt",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['driver'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'f1_driver_name', 'lc_hub_commit_hash': '82b0edbff23516d995f623197448345b3e18a1c41106b1986d8a9c511fd9c3e9'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a steward part of the FIA, moderating F1.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['driver'], input_types={}, partial_variables={}, template='What is the car number of {driver}, and which team does he drive for?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:22:12.341408Z",
     "start_time": "2025-10-06T11:22:12.295162Z"
    }
   },
   "source": [
    "hydrated_prompt = prompt.invoke({\"driver\": \"Max Verstappen?\"})\n",
    "hydrated_prompt"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a steward part of the FIA, moderating F1.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the car number of Max Verstappen?, and which team does he drive for?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:22:24.960707Z",
     "start_time": "2025-10-06T11:22:23.132360Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CNdaKIvuMNi4bevLoEqnvF2E5zdYB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Max Verstappen drives for the Red Bull Racing team and his car number is 1.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759749744, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=18, prompt_tokens=43, total_tokens=61, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:22:39.796583Z",
     "start_time": "2025-10-06T11:22:39.466491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"f1_driver_name\", include_model=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:337: UserWarning: WARNING! extra_headers is not default parameter.\n",
      "                extra_headers was transferred to model_kwargs.\n",
      "                Please confirm that extra_headers is what you intended.\n",
      "  obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:22:42.150428Z",
     "start_time": "2025-10-06T11:22:42.146231Z"
    }
   },
   "cell_type": "code",
   "source": "prompt",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['driver'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'f1_driver_name', 'lc_hub_commit_hash': '82b0edbff23516d995f623197448345b3e18a1c41106b1986d8a9c511fd9c3e9'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a steward part of the FIA, moderating F1.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['driver'], input_types={}, partial_variables={}, template='What is the car number of {driver}, and which team does he drive for?'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10b5dd2b0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10b5dde80>, root_client=<openai.OpenAI object at 0x10b5ddf40>, root_async_client=<openai.AsyncOpenAI object at 0x10b5dd940>, model_name='o4-mini', model_kwargs={'extra_headers': {}}, openai_api_key=SecretStr('**********'), top_p=1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:23:17.044692Z",
     "start_time": "2025-10-06T11:23:05.106015Z"
    }
   },
   "source": "prompt.invoke({\"driver\": \"Kimi Andrea Antonelli\"})",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Andrea Kimi Antonelli currently races in the FIA Formula 2 Championship for Prema Racing and carries car number 16. Heâ€™s also a member of the Ferrari Driver Academy and has been announced as a Williams Racing driver from the start of the 2026 Formula 1 season.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 971, 'prompt_tokens': 44, 'total_tokens': 1015, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o4-mini-2025-04-16', 'system_fingerprint': None, 'id': 'chatcmpl-CNdazCxezetmC0wfKv1ZXDyqMRL2Z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--15471449-c6ac-4b36-80ab-e45b0592347e-0', usage_metadata={'input_tokens': 44, 'output_tokens': 971, 'total_tokens': 1015, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:24:23.975996Z",
     "start_time": "2025-10-06T11:24:23.652867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"f1_driver_name:a6b71350\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:24:44.116002Z",
     "start_time": "2025-10-06T11:24:42.677218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "hydrated_prompt = prompt.invoke({\"driver\": \"Lewis Hamilton\", \"year\": \"2006\"})\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CNdcZu9IgXBrQQvizpvpPFlT8bwU7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In the 2006 Formula One season, Lewis Hamilton drove for the McLaren team, and his car number was 2.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759749883, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=26, prompt_tokens=46, total_tokens=72, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:25:58.887551Z",
     "start_time": "2025-10-06T11:25:54.536643Z"
    }
   },
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "\n",
    "client=Client()\n",
    "\n",
    "f1_prompt = \"\"\"You are an F1 race engineer.\n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak Dutch, make sure you only answer your users with Dutch.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "f1_prompt_template = ChatPromptTemplate.from_template(f1_prompt)\n",
    "client.push_prompt(\"f1-rag-prompt\", object=f1_prompt_template)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/f1-rag-prompt/072858a5?organizationId=b596d003-75cc-4859-ab5f-9c3358306b32'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T11:26:25.994034Z",
     "start_time": "2025-10-06T11:26:22.773803Z"
    }
   },
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "client=Client()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "french_prompt_template = ChatPromptTemplate.from_template(f1_prompt)\n",
    "chain = french_prompt_template | model\n",
    "client.push_prompt(\"f1-runnable-sequence\", object=chain)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/f1-runnable-sequence/b1f2e346?organizationId=b596d003-75cc-4859-ab5f-9c3358306b32'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
